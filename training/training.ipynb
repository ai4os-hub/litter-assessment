{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook for training the Litter Detection Model (PLD) on custom data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import requests\n",
    "import itertools\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.v2 as v2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torchvision import models\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define methods for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_model(destination_dir='./models',\n",
    "                   base_url='https://share.services.ai4os.eu/index.php/s/cA8j9bqNsJJfSkg/download/',\n",
    "                   model_filename='densenet121.pth'):\n",
    "\n",
    "    os.makedirs(destination_dir, exist_ok=True)\n",
    "    full_url = f\"{base_url}{model_filename}\"\n",
    "    destination_path = os.path.join(destination_dir, model_filename)\n",
    "\n",
    "    try:\n",
    "        response = requests.get(full_url, verify=False, stream=True)\n",
    "        response.raise_for_status()  # Raise an error on bad status\n",
    "\n",
    "        with open(destination_path, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "\n",
    "        print(f\"Model downloaded successfully to {destination_path}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to download the model: {e}\")\n",
    "\n",
    "def load_model(model_path, device, num_old_classes, num_classes): \n",
    "    model=models.densenet121(pretrained=False)\n",
    "    model.classifier=nn.Linear(model.classifier.in_features, num_old_classes)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=torch.device(device)),strict=False)\n",
    "    model.classifier=nn.Linear(model.classifier.in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "def modify_model(model, num_classes):\n",
    "    model.classifier=nn.Linear(model.classifier.in_features, num_classes)\n",
    "    return model   \n",
    "\n",
    "def load_labels(label_path):\n",
    "    with open(label_path, 'r') as f:\n",
    "        label_file=yaml.safe_load(f)\n",
    "    labels_old=label_file['label']['label old']\n",
    "    labels=label_file['label']['label new']\n",
    "    return labels_old, labels\n",
    "\n",
    "def training_epoch(model, train_data_loader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    size = len(train_data_loader)\n",
    "    correct, total = 0, 0\n",
    "    for batch, (X, y) in enumerate(train_data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 100 == 0:\n",
    "            print(f'loss: {loss.item():>.7} {batch}/{size}')\n",
    "        correct += (torch.argmax(pred, 1) == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    return loss, correct / total\n",
    "    \n",
    "def val(model, val_data_loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    true_vals = list()\n",
    "    pred_vals = list()\n",
    "    val_loss = list()\n",
    "    with torch.no_grad():\n",
    "        for X, y in val_data_loader:\n",
    "            X = X.to(device)\n",
    "            pred = model(X).cpu()\n",
    "            pred_vals.append(torch.argmax(pred, 1).numpy()[0])\n",
    "            true_vals.append(y.numpy()[0])\n",
    "            val_loss.append(loss_fn(pred, y).item())\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(true_vals, pred_vals, average='weighted',zero_division=0)\n",
    "    accuracy = accuracy_score(true_vals, pred_vals)\n",
    "    return precision, recall, f1_score, np.mean(val_loss), accuracy\n",
    "    \n",
    "def train(num_epochs, model, train_data_loader,test_data_loader, optimizer, loss_fn, device, log_path):\n",
    "    train_losses, val_losses = [], []\n",
    "    train_acc, val_acc = [], []\n",
    "    metric_results = { m: list() for m in ['loss', 'precision', 'recall', 'f1-score'] }\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
    "        train_loss, train_accuracy = training_epoch(model, train_data_loader, optimizer, loss_fn, device)\n",
    "        metric = val(model, test_data_loader, loss_fn, device)\n",
    "        val_loss=metric[3]\n",
    "        val_accuracy = metric[4]\n",
    "\n",
    "        val_losses.append(val_loss)\n",
    "        train_losses.append(train_loss.item())\n",
    "        train_acc.append(train_accuracy)\n",
    "        val_acc.append(val_accuracy)\n",
    "        \n",
    "        metric_results['loss'].append(train_loss.cpu().item())\n",
    "        metric_results['precision'].append(metric[0])\n",
    "        metric_results['recall'].append(metric[1])\n",
    "        metric_results['f1-score'].append(metric[2])\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            with open(os.path.join(log_path, f'metrics.json'), 'w') as file:\n",
    "                json.dump(json.dumps(metric_results), file)\n",
    "            torch.save(model.state_dict(), os.path.join(log_path, f'checkpoint_{epoch + 1}_weights.pth'))\n",
    "        print(f\"Precision: {metric[0]} Recall: {metric[1]} F1-Score: {metric[2]}\")\n",
    "    print(\"Done\")\n",
    "    return model, train_losses, val_losses, train_acc, val_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods for model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_data_loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    true_vals = list()\n",
    "    pred_vals = list()\n",
    "    test_loss = list()\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_data_loader:\n",
    "            X = X.to(device)\n",
    "            pred = model(X).cpu()\n",
    "            pred_vals.append(torch.argmax(pred, 1).numpy()[0])\n",
    "            true_vals.append(y.numpy()[0])\n",
    "            test_loss.append(loss_fn(pred, y).item())\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(true_vals, pred_vals, average='weighted',zero_division=0)\n",
    "    return precision, recall, f1_score\n",
    "\n",
    "def plot_losses(train_losses, test_losses):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(train_losses, label='Training', linewidth=3)\n",
    "    plt.plot(test_losses, label='Validation', linewidth=3)\n",
    "    plt.xlabel('Epochs', fontsize=22)\n",
    "    plt.ylabel('Loss', fontsize=22)\n",
    "    plt.xticks(fontsize=22)\n",
    "    plt.yticks(fontsize=22)\n",
    "    plt.title(f'DenseNet121', fontsize=24)\n",
    "    plt.legend(fontsize=22)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_acc(train_acc, test_acc):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(train_acc, label='Training', linewidth=3)\n",
    "    plt.plot(test_acc, label='Validation', linewidth=3)\n",
    "    plt.xlabel('Epochs', fontsize=22)\n",
    "    plt.ylabel('Accuracy', fontsize=22)\n",
    "    plt.xticks(fontsize=22)\n",
    "    plt.yticks(fontsize=22)\n",
    "    plt.title(f'DenseNet121', fontsize=24)\n",
    "    plt.legend(fontsize=22)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset class and data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dir, labels, transform=None, split='train', seed=35, train_split=0.7, val_split=0.15):\n",
    "        self.dir=dir\n",
    "        self.classes=labels\n",
    "        label_to_index = {label: index for index, label in enumerate(self.classes)}\n",
    "        data = [[os.path.join(dir, u_dir, images) for images in os.listdir(os.path.join(dir, u_dir))] for u_dir in os.listdir(dir)]\n",
    "        data = list(itertools.chain.from_iterable(data))\n",
    "        self.data = np.array([[label_to_index[name.split('/')[-2]], name] for name in data if name.split('/')[-1][-3:] == 'png'])\n",
    "        X_train, X_temp = train_test_split(self.data, train_size=train_split, random_state=seed, stratify=self.data[:, 0])\n",
    "        X_val, X_test = train_test_split(X_temp, test_size=val_split / (1 - train_split), random_state=seed, stratify=X_temp[:, 0])\n",
    "        \n",
    "        if split == 'train':\n",
    "            self.data = X_train\n",
    "        elif split == 'val':\n",
    "            self.data = X_val\n",
    "        else:\n",
    "            self.data = X_test \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label, img_path = self.data[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img) \n",
    "        return img, int(label)\n",
    "    \n",
    "train_transform = v2.Compose([\n",
    "            v2.PILToTensor(),\n",
    "            v2.Resize((128, 128), interpolation=v2.InterpolationMode.NEAREST),\n",
    "            v2.RandomHorizontalFlip(p=0.5),\n",
    "            v2.RandomVerticalFlip(p=0.5),\n",
    "            # v2.RandomRotation(45),\n",
    "            # v2.ColorJitter(brightness=0.2),\n",
    "            # v2.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "            # v2.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5.)),\n",
    "            v2.ConvertImageDtype(torch.float32),\n",
    "            # v2.Lambda(lambda x: x / 255.)\n",
    "    ])\n",
    "\n",
    "test_transform = v2.Compose([\n",
    "            v2.PILToTensor(),\n",
    "            v2.Resize((128, 128), interpolation=v2.InterpolationMode.NEAREST),\n",
    "            v2.ConvertImageDtype(torch.float32),\n",
    "            v2.Lambda(lambda x: x / 255.)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main skript for running the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set paths\n",
    "model_path=os.path.join(os.getcwd(),'models', 'densenet121.pth')\n",
    "label_path=os.path.join(os.getcwd(), 'configs/labels.yaml')\n",
    "data_path=os.path.join(os.getcwd(), 'data')\n",
    "log_path=os.path.join(os.getcwd(), 'logs')\n",
    "new_model_path=f'new_model.pth'\n",
    "\n",
    "#download pretrained densenet121 weights\n",
    "download_model()\n",
    "\n",
    "#Set training parameters\n",
    "num_epochs=1\n",
    "learning_rate=0.001\n",
    "batch_size=32\n",
    "num_workers=1\n",
    "device=torch.device(f\"cuda:{torch.cuda.current_device()}\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Training is running on {device}')\n",
    "\n",
    "#Load model and labels\n",
    "labels_old, labels=load_labels(label_path)\n",
    "num_new_classes=len(labels)\n",
    "num_old_classes=len(labels_old)\n",
    "model=load_model(model_path, device, num_old_classes, num_new_classes)\n",
    "\n",
    "optimizer=Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = CrossEntropyLoss().to(device)\n",
    "\n",
    "#Initialize train and test data loaders\n",
    "train_dataset = CustomDataset(data_path, split='train', transform=train_transform, labels=labels)\n",
    "val_dataset = CustomDataset(data_path, split='val', transform=test_transform, labels=labels)\n",
    "test_dataset = CustomDataset(data_path, split='test', transform=test_transform, labels=labels)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=1, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "#Modify model to new input data\n",
    "mod_model=modify_model(model, num_new_classes).to(device)\n",
    "\n",
    "#Retrain modified model\n",
    "finetuned_model,train_losses, val_losses, train_acc, val_acc =train(num_epochs, mod_model, train_data_loader, val_data_loader, optimizer, loss_fn, device, log_path)\n",
    "\n",
    "#Save finetuned model\n",
    "torch.save(finetuned_model.state_dict(), new_model_path)\n",
    "print(f\"Model saved: {new_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cleluschko/anaconda3/envs/iMagine/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/cleluschko/anaconda3/envs/iMagine/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_129611/777536841.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_file, map_location=torch.device(device)),strict=False)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(model_file, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(device)),strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 13\u001b[0m test_precision, test_recall, test_f1_score \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_precision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Recall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_recall\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[49], line 7\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, test_data_loader, loss_fn, device)\u001b[0m\n\u001b[1;32m      5\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m test_data_loader:\n\u001b[1;32m      8\u001b[0m         X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m         pred \u001b[38;5;241m=\u001b[39m model(X)\u001b[38;5;241m.\u001b[39mcpu()\n",
      "File \u001b[0;32m~/anaconda3/envs/iMagine/lib/python3.9/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/envs/iMagine/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1448\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1448\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1451\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/iMagine/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1412\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1409\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1410\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1411\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1412\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1413\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1414\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/iMagine/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1243\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1231\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1232\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1241\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1242\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1243\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1244\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1245\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1246\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1247\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1248\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/iMagine/lib/python3.9/multiprocessing/queues.py:122\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# unserialize the data after having released the lock\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ForkingPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/iMagine/lib/python3.9/site-packages/torch/multiprocessing/reductions.py:112\u001b[0m, in \u001b[0;36mrebuild_tensor\u001b[0;34m(cls, storage, metadata)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrebuild_tensor\u001b[39m(\u001b[38;5;28mcls\u001b[39m, storage, metadata):\n\u001b[1;32m    111\u001b[0m     storage_offset, size, stride, requires_grad \u001b[38;5;241m=\u001b[39m metadata\n\u001b[0;32m--> 112\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rebuild_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mparameter\u001b[38;5;241m.\u001b[39mParameter:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;66;03m# we have to pass requires_grad into constructor, rather than set it as an\u001b[39;00m\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;66;03m# attribute later, because it's an important check for Integer Tensors to\u001b[39;00m\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;66;03m# have requires_grad=False (or else they raise an error)\u001b[39;00m\n\u001b[1;32m    117\u001b[0m         t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mparameter\u001b[38;5;241m.\u001b[39mParameter(t, requires_grad\u001b[38;5;241m=\u001b[39mrequires_grad)\n",
      "File \u001b[0;32m~/anaconda3/envs/iMagine/lib/python3.9/site-packages/torch/_utils.py:175\u001b[0m, in \u001b[0;36m_rebuild_tensor\u001b[0;34m(storage, storage_offset, size, stride)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_rebuild_tensor\u001b[39m(storage, storage_offset, size, stride):\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# first construct a tensor with the correct dtype/device\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mempty((\u001b[38;5;241m0\u001b[39m,), dtype\u001b[38;5;241m=\u001b[39mstorage\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mstorage\u001b[38;5;241m.\u001b[39m_untyped_storage\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_untyped_storage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_file='new_model.pth'\n",
    "\n",
    "labels_old, labels=load_labels(label_path)\n",
    "num_new_classes=len(labels)\n",
    "\n",
    "device=torch.device(f\"cuda:{torch.cuda.current_device()}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model=models.densenet121(pretrained=False)\n",
    "model.classifier=nn.Linear(model.classifier.in_features, num_new_classes)\n",
    "model.load_state_dict(torch.load(model_file, map_location=torch.device(device)),strict=False)\n",
    "model.to(device)\n",
    "\n",
    "test_precision, test_recall, test_f1_score = test(model, test_data_loader, loss_fn, device)\n",
    "print(f\"Test Precision: {test_precision}\")\n",
    "print(f\"Test Recall: {test_recall}\")\n",
    "print(f\"Test F1-Score: {test_f1_score}\")\n",
    "\n",
    "plot_losses(train_losses, val_losses)\n",
    "plot_acc(train_acc, val_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iMagine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
